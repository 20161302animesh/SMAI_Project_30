{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Proj-v1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Zitq1SavaNeb",
        "colab_type": "code",
        "outputId": "7dfc59ef-f9b9-448f-df20-0d6239adc308",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# Code to read csv file into Colaboratory:\n",
        "!pip install -U -q PyDrive\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "link = 'https://drive.google.com/open?id=1Ka7fNnL71IH-BV010DhTLU9Drlmqt3o9'\n",
        "fluff, id = link.split('=')\n",
        "print (id) # Verify that you have everything after '='\n",
        "downloaded = drive.CreateFile({'id':id}) \n",
        "downloaded.GetContentFile('rumour.npy')  \n",
        "file_dict = np.load('rumour.npy',allow_pickle=True)\n",
        "\n",
        "link1 = 'https://drive.google.com/open?id=1KaglTR_T2tQcxsHl5jSuXtmlcWJTk4ZY'\n",
        "fluff1, id1 = link1.split('=')\n",
        "print (id1) # Verify that you have everything after '='\n",
        "downloaded1 = drive.CreateFile({'id':id1}) \n",
        "downloaded1.GetContentFile('fakenews.npy')  \n",
        "file_dict1 = np.load('fakenews.npy',allow_pickle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1Ka7fNnL71IH-BV010DhTLU9Drlmqt3o9\n",
            "1KaglTR_T2tQcxsHl5jSuXtmlcWJTk4ZY\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MQnT980ZfRZc",
        "colab_type": "code",
        "outputId": "343206fe-2475-45a6-ecc2-0f44b540bb32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "out1Val = file_dict[:,1]\n",
        "in1Val = file_dict[:,0]\n",
        "print(in1Val.shape)\n",
        "out2Val = file_dict1[:,1]\n",
        "in2Val = file_dict1[:,0]\n",
        "print(in2Val.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5331,)\n",
            "(5000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Edh2VS_QA2Si",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def pad_along_axis(array: np.ndarray, target_length, axis=0):\n",
        "\n",
        "    pad_size = target_length - array.shape[axis]\n",
        "    axis_nb = len(array.shape)\n",
        "\n",
        "    if pad_size < 0:\n",
        "        return array[:target_length]\n",
        "    npad = [(0, 0) for x in range(axis_nb)]\n",
        "    npad[axis] = (0, pad_size)\n",
        "\n",
        "    b = np.pad(array, pad_width=npad, mode='constant', constant_values=0)\n",
        "\n",
        "    return b\n",
        "  \n",
        "\n",
        "shapes = [ar.shape[0] for ar in in1Val]\n",
        "maxLeng1 =  np.max(shapes)\n",
        "shapes = [ar.shape[0] for ar in in2Val]\n",
        "maxLeng2 =  np.max(shapes)\n",
        "maxLeng  = maxLeng1\n",
        "if(maxLeng < maxLeng2):\n",
        "  maxLeng = maxLeng2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0ZHaU6mJlmFU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "timeSteps = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k9AXigatlk7T",
        "colab_type": "code",
        "outputId": "e25dcec6-bdbf-4898-cdf0-b0b186b6863d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "in2ValX = in1Val\n",
        "temp = [pad_along_axis(in2ValAR, timeSteps, axis=0) for in2ValAR in in2ValX]\n",
        "# in1Vali = [np.pad(in1ValAR, (0,maxLeng-in1ValAR.shape[0]), 'constant', constant_values=(0, 0)) for in1ValAR in in1ValX]\n",
        "# shapes1 = [[ar.shape] for ar in in1Vali]\n",
        "#print(shapes1)\n",
        "in1Vali = np.array(temp)\n",
        "print(in1Vali.shape)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5331, 200, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "po9Fx9q08Lee",
        "colab_type": "code",
        "outputId": "caa75feb-9060-458c-de55-280eff2776d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "in1ValX = None\n",
        "in1ValX = in2Val\n",
        "temp = [pad_along_axis(in1ValAR, timeSteps, axis=0) for in1ValAR in in1ValX]\n",
        "# in1Vali = [np.pad(in1ValAR, (0,maxLeng-in1ValAR.shape[0]), 'constant', constant_values=(0, 0)) for in1ValAR in in1ValX]\n",
        "#print(shapes1)\n",
        "in2Vali = np.array(temp)\n",
        "print(in2Vali.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(5000, 200, 300)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "O-VXdSEwjKS7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(np.unique(out1Val,return_counts=True))\n",
        "out1Vali = [1 if val=='rumours' else 0 for val in out1Val]\n",
        "out1Vali = np.array(out1Vali)\n",
        "# print(np.unique(out1Vali,return_counts=True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uod8bzmZlF-H",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print(np.unique(out2Val,return_counts=True))\n",
        "def findInt(valu):\n",
        "  if valu == 'agree':\n",
        "    return np.array([1,0,0,0])\n",
        "  elif valu == 'disagree':\n",
        "    return np.array([0,1,0,0])\n",
        "  elif valu == 'discuss':\n",
        "    return np.array([0,0,1,0])\n",
        "  else:\n",
        "    return np.array([0,0,0,1])\n",
        "out2Vali = [findInt(val) for val in out2Val]\n",
        "out2Vali = np.array(out2Vali)\n",
        "#print(out2Vali.shape,out2Val.shape,out2Val[0:5],out2Vali[0:5,:])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O_QOVAM-pUQo",
        "colab_type": "code",
        "outputId": "0f28afc6-8e25-4b19-fc48-b61b595d2c5e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# from sklearn.cross_validation import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM, GRU\n",
        "from keras.optimizers import RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "# Data = [[[(i+j)/100] for i in np.arange(5)] for j in np.arange(100)]\n",
        "# target = [1 if (i%5)==0 else 0 for i in np.arange(100)]\n",
        "# x_train = np.array(Data,dtype=float)\n",
        "# y_train = np.array(target,dtype=float)\n",
        "# # print(x_train,y_train)\n",
        "# Data = [[[(i+j)/200] for i in np.arange(5)] for j in np.arange(100)]\n",
        "# target = [1 if (i%5)==0 else 0 for i in np.arange(100)]\n",
        "# x_test = np.array(Data,dtype=float)\n",
        "# y_test = np.array(target,dtype=float)\n",
        "# # print(x_test,y_test)\n",
        "# # x_train,x_test,y_train,y_test = train_test_split(data,target,size=0.2,random_state=4)\n",
        "# model=Sequential()\n",
        "# model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=False))\n",
        "# # model.add(Dense((1),activation='softmax'))\n",
        "# model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])\n",
        "# model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HifFfsz0xNgk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# history = model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))\n",
        "# results = model.predict(x_test)\n",
        "# plt.scatter(np.arange(100),results,c='r')\n",
        "# plt.scatter(np.arange(100),y_test,c='g')\n",
        "# plt.show()\n",
        "\n",
        "# plt.plot(history.history['loss'])\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "h52kGMOQfP9N",
        "colab_type": "code",
        "outputId": "2bfc1aff-1673-4171-fb50-539feb29ac72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "from keras.layers import Input,concatenate\n",
        "from keras.models import Model\n",
        "# define two sets of inputs\n",
        "print\n",
        "inputA = Input(shape=(None,300))\n",
        "inputB = Input(shape=(None,300))\n",
        " \n",
        "# the first branch operates on the first input\n",
        "x1 = Dense(300, activation=\"linear\")(inputA)\n",
        "x1 = Model(inputs=inputA, outputs=x1)\n",
        " \n",
        "# the second branch opreates on the second input\n",
        "\n",
        "x2 = Dense(300, activation=\"linear\")(inputB)\n",
        "x2 = Model(inputs=inputB, outputs=x2)\n",
        "\n",
        "combinedinput = concatenate([x1.output, x2.output])\n",
        "# combinedinputDense = Dense(300, activation=\"linear\")(combinedinput)\n",
        "sharedLOut = GRU((300),return_sequences=True)(combinedinput)\n",
        "# sharedLayerModel = Model(inputs=combinedinput, output=sharedLOut)\n",
        "\n",
        "model1Input = concatenate([x1.output, sharedLOut])\n",
        "model1Out = GRU((4),return_sequences=False)(model1Input)\n",
        "# model1 = Model(inputs=model1Input, output=model1Out)\n",
        "\n",
        "\n",
        "model2Input = concatenate([x2.output, sharedLOut])\n",
        "model2Out = GRU((1),return_sequences=False)(model2Input)\n",
        "# model2 = Model(inputs=model2Input, output=model2Out)\n",
        "model = Model(input=[inputA,inputB], outputs=[model1Out,model2Out])\n",
        "optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)\n",
        "model.compile(loss='mse', optimizer=optimizer)\n",
        "model.summary()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, None, 300)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            (None, None, 300)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, None, 300)    90300       input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, None, 300)    90300       input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, None, 600)    0           dense_1[0][0]                    \n",
            "                                                                 dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     (None, None, 300)    810900      concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, None, 600)    0           dense_1[0][0]                    \n",
            "                                                                 gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, None, 600)    0           dense_2[0][0]                    \n",
            "                                                                 gru_1[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "gru_2 (GRU)                     (None, 4)            7260        concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "gru_3 (GRU)                     (None, 1)            1806        concatenate_3[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 1,000,566\n",
            "Trainable params: 1,000,566\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:31: UserWarning: Update your `Model` call to the Keras 2 API: `Model(outputs=[<tf.Tenso..., inputs=[<tf.Tenso...)`\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "XAi9Q95e8WEO",
        "colab_type": "code",
        "outputId": "61e8c905-8d0b-4c79-fccd-c1946f1253e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3485
        }
      },
      "cell_type": "code",
      "source": [
        "# history = {}\n",
        "# results = {}\n",
        "# for j in np.arange(10):\n",
        "#   i = j\n",
        "#   X2_train = in1Val[i]\n",
        "#   Y2_train = out1Vali[i]\n",
        "#   X2_train = X2_train.reshape(1,*X2_train.shape)\n",
        "#   Y2_train = Y2_train.reshape(1,1)\n",
        "#   X1_train = in2Val[i]\n",
        "#   Y1_train = out2Vali[i]\n",
        "#   X1_train = X1_train.reshape(1,*X1_train.shape)\n",
        "#   Y1_train = Y1_train.reshape(1,*Y1_train.shape)\n",
        "#   i = int(j/2)\n",
        "#   X2_test = in1Val[i]\n",
        "#   Y2_test = out1Vali[i]\n",
        "#   X2_test = X2_test.reshape(1,*X2_test.shape)\n",
        "#   Y2_test = Y2_test.reshape(1,1)\n",
        "#   X1_test = in2Val[i]\n",
        "#   Y1_test = out2Vali[i]\n",
        "#   X1_test = X1_test.reshape(1,*X1_test.shape)\n",
        "#   Y1_test = Y1_test.reshape(1,*Y1_test.shape)\n",
        "# history = model.fit([X1_train,X2_train],[Y1_train,Y2_train],epochs=10,validation_data=([X1_test,X2_test],[Y1_test,Y2_test]))\n",
        "# results = model.predict(x_test)\n",
        "history = model.fit([in2Vali[0:4500],in1Vali[0:4500]],[out2Vali[0:4500],out1Vali[0:4500]],batch_size=100,epochs=100,validation_data=([in2Vali[4500:5000],in1Vali[4500:5000]],[out2Vali[4500:5000],out1Vali[4500:5000]]))\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 4500 samples, validate on 500 samples\n",
            "Epoch 1/100\n",
            "4500/4500 [==============================] - 199s 44ms/step - loss: 0.3644 - gru_2_loss: 0.1199 - gru_3_loss: 0.2445 - val_loss: 0.1737 - val_gru_2_loss: 0.1133 - val_gru_3_loss: 0.0604\n",
            "Epoch 2/100\n",
            "4500/4500 [==============================] - 185s 41ms/step - loss: 0.3404 - gru_2_loss: 0.1098 - gru_3_loss: 0.2305 - val_loss: 0.2676 - val_gru_2_loss: 0.1121 - val_gru_3_loss: 0.1555\n",
            "Epoch 3/100\n",
            "4500/4500 [==============================] - 185s 41ms/step - loss: 0.3395 - gru_2_loss: 0.1094 - gru_3_loss: 0.2301 - val_loss: 0.2364 - val_gru_2_loss: 0.1109 - val_gru_3_loss: 0.1254\n",
            "Epoch 4/100\n",
            "4500/4500 [==============================] - 185s 41ms/step - loss: 0.3390 - gru_2_loss: 0.1091 - gru_3_loss: 0.2299 - val_loss: 0.1962 - val_gru_2_loss: 0.1116 - val_gru_3_loss: 0.0846\n",
            "Epoch 5/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3387 - gru_2_loss: 0.1088 - gru_3_loss: 0.2299 - val_loss: 0.2331 - val_gru_2_loss: 0.1107 - val_gru_3_loss: 0.1225\n",
            "Epoch 6/100\n",
            "4500/4500 [==============================] - 185s 41ms/step - loss: 0.3372 - gru_2_loss: 0.1084 - gru_3_loss: 0.2288 - val_loss: 0.1836 - val_gru_2_loss: 0.1126 - val_gru_3_loss: 0.0710\n",
            "Epoch 7/100\n",
            "4500/4500 [==============================] - 186s 41ms/step - loss: 0.3377 - gru_2_loss: 0.1086 - gru_3_loss: 0.2291 - val_loss: 0.2969 - val_gru_2_loss: 0.1128 - val_gru_3_loss: 0.1841\n",
            "Epoch 8/100\n",
            "4500/4500 [==============================] - 185s 41ms/step - loss: 0.3367 - gru_2_loss: 0.1086 - gru_3_loss: 0.2281 - val_loss: 0.2407 - val_gru_2_loss: 0.1113 - val_gru_3_loss: 0.1295\n",
            "Epoch 9/100\n",
            "4500/4500 [==============================] - 182s 40ms/step - loss: 0.3371 - gru_2_loss: 0.1083 - gru_3_loss: 0.2288 - val_loss: 0.2353 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1248\n",
            "Epoch 10/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3361 - gru_2_loss: 0.1085 - gru_3_loss: 0.2276 - val_loss: 0.2124 - val_gru_2_loss: 0.1114 - val_gru_3_loss: 0.1010\n",
            "Epoch 11/100\n",
            "4500/4500 [==============================] - 183s 41ms/step - loss: 0.3368 - gru_2_loss: 0.1086 - gru_3_loss: 0.2282 - val_loss: 0.2170 - val_gru_2_loss: 0.1114 - val_gru_3_loss: 0.1056\n",
            "Epoch 12/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3369 - gru_2_loss: 0.1084 - gru_3_loss: 0.2286 - val_loss: 0.2110 - val_gru_2_loss: 0.1109 - val_gru_3_loss: 0.1000\n",
            "Epoch 13/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3369 - gru_2_loss: 0.1083 - gru_3_loss: 0.2286 - val_loss: 0.2244 - val_gru_2_loss: 0.1106 - val_gru_3_loss: 0.1138\n",
            "Epoch 14/100\n",
            "4500/4500 [==============================] - 180s 40ms/step - loss: 0.3365 - gru_2_loss: 0.1082 - gru_3_loss: 0.2284 - val_loss: 0.2681 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1576\n",
            "Epoch 15/100\n",
            "4500/4500 [==============================] - 182s 40ms/step - loss: 0.3365 - gru_2_loss: 0.1082 - gru_3_loss: 0.2282 - val_loss: 0.2247 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1142\n",
            "Epoch 16/100\n",
            "4500/4500 [==============================] - 182s 41ms/step - loss: 0.3368 - gru_2_loss: 0.1084 - gru_3_loss: 0.2284 - val_loss: 0.2320 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1216\n",
            "Epoch 17/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3363 - gru_2_loss: 0.1081 - gru_3_loss: 0.2282 - val_loss: 0.1942 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.0838\n",
            "Epoch 18/100\n",
            "4500/4500 [==============================] - 184s 41ms/step - loss: 0.3367 - gru_2_loss: 0.1082 - gru_3_loss: 0.2285 - val_loss: 0.2483 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1378\n",
            "Epoch 19/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3364 - gru_2_loss: 0.1081 - gru_3_loss: 0.2283 - val_loss: 0.2220 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1116\n",
            "Epoch 20/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3366 - gru_2_loss: 0.1082 - gru_3_loss: 0.2284 - val_loss: 0.2221 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1118\n",
            "Epoch 21/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3361 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2252 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1148\n",
            "Epoch 22/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1080 - gru_3_loss: 0.2279 - val_loss: 0.2173 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1069\n",
            "Epoch 23/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1081 - gru_3_loss: 0.2279 - val_loss: 0.2071 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.0968\n",
            "Epoch 24/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3362 - gru_2_loss: 0.1080 - gru_3_loss: 0.2282 - val_loss: 0.2089 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.0985\n",
            "Epoch 25/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3362 - gru_2_loss: 0.1082 - gru_3_loss: 0.2281 - val_loss: 0.2521 - val_gru_2_loss: 0.1106 - val_gru_3_loss: 0.1415\n",
            "Epoch 26/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3364 - gru_2_loss: 0.1081 - gru_3_loss: 0.2283 - val_loss: 0.2144 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1041\n",
            "Epoch 27/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3361 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2180 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1077\n",
            "Epoch 28/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3361 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2327 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1224\n",
            "Epoch 29/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1080 - gru_3_loss: 0.2277 - val_loss: 0.2432 - val_gru_2_loss: 0.1110 - val_gru_3_loss: 0.1323\n",
            "Epoch 30/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1079 - gru_3_loss: 0.2281 - val_loss: 0.2445 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1340\n",
            "Epoch 31/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2156 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1053\n",
            "Epoch 32/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3359 - gru_2_loss: 0.1080 - gru_3_loss: 0.2279 - val_loss: 0.2322 - val_gru_2_loss: 0.1106 - val_gru_3_loss: 0.1216\n",
            "Epoch 33/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2401 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1297\n",
            "Epoch 34/100\n",
            "4500/4500 [==============================] - 180s 40ms/step - loss: 0.3361 - gru_2_loss: 0.1079 - gru_3_loss: 0.2282 - val_loss: 0.2209 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1105\n",
            "Epoch 35/100\n",
            "4500/4500 [==============================] - 181s 40ms/step - loss: 0.3360 - gru_2_loss: 0.1080 - gru_3_loss: 0.2280 - val_loss: 0.2186 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1082\n",
            "Epoch 36/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2226 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1122\n",
            "Epoch 37/100\n",
            "4500/4500 [==============================] - 178s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2279 - val_loss: 0.2436 - val_gru_2_loss: 0.1112 - val_gru_3_loss: 0.1323\n",
            "Epoch 38/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3359 - gru_2_loss: 0.1080 - gru_3_loss: 0.2280 - val_loss: 0.2188 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1083\n",
            "Epoch 39/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3361 - gru_2_loss: 0.1080 - gru_3_loss: 0.2281 - val_loss: 0.2355 - val_gru_2_loss: 0.1109 - val_gru_3_loss: 0.1245\n",
            "Epoch 40/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2402 - val_gru_2_loss: 0.1111 - val_gru_3_loss: 0.1291\n",
            "Epoch 41/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1080 - gru_3_loss: 0.2280 - val_loss: 0.2341 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1239\n",
            "Epoch 42/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1079 - gru_3_loss: 0.2279 - val_loss: 0.2146 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1043\n",
            "Epoch 43/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1080 - gru_3_loss: 0.2280 - val_loss: 0.2239 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1136\n",
            "Epoch 44/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1080 - gru_3_loss: 0.2276 - val_loss: 0.2117 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1014\n",
            "Epoch 45/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1081 - gru_3_loss: 0.2276 - val_loss: 0.2041 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.0938\n",
            "Epoch 46/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1079 - gru_3_loss: 0.2279 - val_loss: 0.2416 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1313\n",
            "Epoch 47/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1080 - gru_3_loss: 0.2276 - val_loss: 0.2119 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1016\n",
            "Epoch 48/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3359 - gru_2_loss: 0.1079 - gru_3_loss: 0.2280 - val_loss: 0.2363 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1259\n",
            "Epoch 49/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3356 - gru_2_loss: 0.1081 - gru_3_loss: 0.2275 - val_loss: 0.2263 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1159\n",
            "Epoch 50/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2450 - val_gru_2_loss: 0.1109 - val_gru_3_loss: 0.1341\n",
            "Epoch 51/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2275 - val_loss: 0.2376 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1271\n",
            "Epoch 52/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2229 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1126\n",
            "Epoch 53/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1079 - gru_3_loss: 0.2279 - val_loss: 0.2338 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1234\n",
            "Epoch 54/100\n",
            "4500/4500 [==============================] - 174s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1079 - gru_3_loss: 0.2279 - val_loss: 0.2187 - val_gru_2_loss: 0.1108 - val_gru_3_loss: 0.1078\n",
            "Epoch 55/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2275 - val_loss: 0.2355 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1250\n",
            "Epoch 56/100\n",
            "4500/4500 [==============================] - 174s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1079 - gru_3_loss: 0.2278 - val_loss: 0.2292 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1188\n",
            "Epoch 57/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1080 - gru_3_loss: 0.2275 - val_loss: 0.2630 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1525\n",
            "Epoch 58/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3362 - gru_2_loss: 0.1082 - gru_3_loss: 0.2280 - val_loss: 0.2402 - val_gru_2_loss: 0.1107 - val_gru_3_loss: 0.1296\n",
            "Epoch 59/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2275 - val_loss: 0.2167 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1065\n",
            "Epoch 60/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2401 - val_gru_2_loss: 0.1106 - val_gru_3_loss: 0.1295\n",
            "Epoch 61/100\n",
            "4500/4500 [==============================] - 174s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1078 - gru_3_loss: 0.2278 - val_loss: 0.2385 - val_gru_2_loss: 0.1106 - val_gru_3_loss: 0.1279\n",
            "Epoch 62/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1079 - gru_3_loss: 0.2278 - val_loss: 0.2353 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1250\n",
            "Epoch 63/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1081 - gru_3_loss: 0.2276 - val_loss: 0.2399 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1296\n",
            "Epoch 64/100\n",
            "4500/4500 [==============================] - 180s 40ms/step - loss: 0.3355 - gru_2_loss: 0.1080 - gru_3_loss: 0.2275 - val_loss: 0.2251 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1148\n",
            "Epoch 65/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2530 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1426\n",
            "Epoch 66/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2263 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1159\n",
            "Epoch 67/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3354 - gru_2_loss: 0.1078 - gru_3_loss: 0.2276 - val_loss: 0.2350 - val_gru_2_loss: 0.1108 - val_gru_3_loss: 0.1242\n",
            "Epoch 68/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3382 - gru_2_loss: 0.1102 - gru_3_loss: 0.2280 - val_loss: 0.2191 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1086\n",
            "Epoch 69/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2437 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1332\n",
            "Epoch 70/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2224 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1121\n",
            "Epoch 71/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3356 - gru_2_loss: 0.1080 - gru_3_loss: 0.2276 - val_loss: 0.2318 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1212\n",
            "Epoch 72/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2276 - val_loss: 0.2184 - val_gru_2_loss: 0.1144 - val_gru_3_loss: 0.1040\n",
            "Epoch 73/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3359 - gru_2_loss: 0.1082 - gru_3_loss: 0.2277 - val_loss: 0.2496 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1392\n",
            "Epoch 74/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3358 - gru_2_loss: 0.1078 - gru_3_loss: 0.2280 - val_loss: 0.2187 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1083\n",
            "Epoch 75/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2276 - val_loss: 0.2400 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1298\n",
            "Epoch 76/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3355 - gru_2_loss: 0.1081 - gru_3_loss: 0.2274 - val_loss: 0.2142 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1038\n",
            "Epoch 77/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1082 - gru_3_loss: 0.2275 - val_loss: 0.2372 - val_gru_2_loss: 0.1102 - val_gru_3_loss: 0.1269\n",
            "Epoch 78/100\n",
            "4500/4500 [==============================] - 180s 40ms/step - loss: 0.3353 - gru_2_loss: 0.1078 - gru_3_loss: 0.2275 - val_loss: 0.2142 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1039\n",
            "Epoch 79/100\n",
            "4500/4500 [==============================] - 181s 40ms/step - loss: 0.3393 - gru_2_loss: 0.1098 - gru_3_loss: 0.2295 - val_loss: 0.2076 - val_gru_2_loss: 0.1122 - val_gru_3_loss: 0.0954\n",
            "Epoch 80/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3357 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2283 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1180\n",
            "Epoch 81/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2374 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1269\n",
            "Epoch 82/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3357 - gru_2_loss: 0.1080 - gru_3_loss: 0.2277 - val_loss: 0.2272 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1167\n",
            "Epoch 83/100\n",
            "4500/4500 [==============================] - 180s 40ms/step - loss: 0.3358 - gru_2_loss: 0.1080 - gru_3_loss: 0.2278 - val_loss: 0.2203 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1100\n",
            "Epoch 84/100\n",
            "4500/4500 [==============================] - 179s 40ms/step - loss: 0.3356 - gru_2_loss: 0.1079 - gru_3_loss: 0.2277 - val_loss: 0.2227 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1123\n",
            "Epoch 85/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3368 - gru_2_loss: 0.1085 - gru_3_loss: 0.2283 - val_loss: 0.2400 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1295\n",
            "Epoch 86/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1079 - gru_3_loss: 0.2278 - val_loss: 0.2311 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1209\n",
            "Epoch 87/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2276 - val_loss: 0.2238 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1133\n",
            "Epoch 88/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1079 - gru_3_loss: 0.2278 - val_loss: 0.2319 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1216\n",
            "Epoch 89/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1081 - gru_3_loss: 0.2276 - val_loss: 0.2314 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1211\n",
            "Epoch 90/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1078 - gru_3_loss: 0.2279 - val_loss: 0.2266 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1161\n",
            "Epoch 91/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3354 - gru_2_loss: 0.1078 - gru_3_loss: 0.2276 - val_loss: 0.2133 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1029\n",
            "Epoch 92/100\n",
            "4500/4500 [==============================] - 178s 40ms/step - loss: 0.3356 - gru_2_loss: 0.1078 - gru_3_loss: 0.2277 - val_loss: 0.2393 - val_gru_2_loss: 0.1109 - val_gru_3_loss: 0.1284\n",
            "Epoch 93/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1078 - gru_3_loss: 0.2278 - val_loss: 0.2217 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1113\n",
            "Epoch 94/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3357 - gru_2_loss: 0.1079 - gru_3_loss: 0.2278 - val_loss: 0.2300 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1198\n",
            "Epoch 95/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3355 - gru_2_loss: 0.1079 - gru_3_loss: 0.2276 - val_loss: 0.2400 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1297\n",
            "Epoch 96/100\n",
            "4500/4500 [==============================] - 175s 39ms/step - loss: 0.3356 - gru_2_loss: 0.1078 - gru_3_loss: 0.2277 - val_loss: 0.2338 - val_gru_2_loss: 0.1108 - val_gru_3_loss: 0.1231\n",
            "Epoch 97/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3354 - gru_2_loss: 0.1078 - gru_3_loss: 0.2276 - val_loss: 0.2302 - val_gru_2_loss: 0.1104 - val_gru_3_loss: 0.1198\n",
            "Epoch 98/100\n",
            "4500/4500 [==============================] - 177s 39ms/step - loss: 0.3353 - gru_2_loss: 0.1079 - gru_3_loss: 0.2274 - val_loss: 0.2123 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1020\n",
            "Epoch 99/100\n",
            "4500/4500 [==============================] - 176s 39ms/step - loss: 0.3360 - gru_2_loss: 0.1081 - gru_3_loss: 0.2280 - val_loss: 0.2362 - val_gru_2_loss: 0.1103 - val_gru_3_loss: 0.1259\n",
            "Epoch 100/100\n",
            "4500/4500 [==============================] - 174s 39ms/step - loss: 0.3353 - gru_2_loss: 0.1078 - gru_3_loss: 0.2275 - val_loss: 0.2448 - val_gru_2_loss: 0.1105 - val_gru_3_loss: 0.1343\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fd5NbObPx7jj",
        "colab_type": "code",
        "outputId": "d1480423-22cf-4ab7-a35b-752cd83fad76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "cell_type": "code",
      "source": [
        "predicted = model.predict([in2Vali[4500:5000],in1Vali[4500:5000]])\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAQUCCIiAigQREQkoEAQEREA/j+/Yv+opBzGYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "iaWu5ymBE2bH",
        "colab_type": "code",
        "outputId": "14faecd2-40d1-4021-da93-64c54a571b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "[predA,predB] = predicted\n",
        "print(predA.shape,predB.shape)\n",
        "actA,actB = out2Vali[4500:5000],out1Vali[4500:5000]\n",
        "actB = actB.reshape(500,1)\n",
        "print(actA.shape,actB.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(500, 4) (500, 1)\n",
            "(500, 4) (500, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bmf0a5nLGf69",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "predA = (predA > 0.5)*1\n",
        "predB = (predB > 0.5)*1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v_F3T6_oMZ8b",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "import seaborn as sns\n",
        "def confusionMatrix(cm,f1mi, f1ma):\n",
        "    #T_class = list(map(int,y_adm_val >= t ))\n",
        "    #out = predict(X_adm_val,Theta,t,Mean,Std)\n",
        "#     cm = confusion_matrix(a, b)\n",
        "    ax= plt.subplot()\n",
        "    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells\n",
        "\n",
        "    # labels, title and ticks\n",
        "    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); \n",
        "    ax.set_title('Confusion Matrix'); \n",
        "    #ax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0'])\n",
        "    print(\"Micro-F1-score\",f1mi)\n",
        "    print(\"Macro-F1-score\",f1ma)\n",
        "#     print(\"precision\",precision_score(T_class,out, average = 'micro'))\n",
        "#     print(\"Accuracy\",accuracy_score(T_class,out))\n",
        "#     print(\"Recall\",recall_score(T_class,out, average = 'micro'))\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nJS8yMI29SOA",
        "colab_type": "code",
        "outputId": "92f66580-74db-4dac-c815-a2d68c7f9d45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 680
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix \n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import classification_report \n",
        "resultsA = confusion_matrix(actA.argmax(axis=1), predA.argmax(axis=1)) \n",
        "f1_scoreAMi = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'micro') \n",
        "f1_scoreAMa = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'macro') \n",
        "# confusionMatrix(resultsA,f1_scoreAMi,f1_scoreAMa)\n",
        "print('Confusion Matrix Test Data - Task 1 : ')\n",
        "print(resultsA) \n",
        "print('Accuracy Score Test Data - Task 1 :',accuracy_score(actA, predA) )\n",
        "print('Report Test Data - Task 1 : ')\n",
        "print(classification_report(actA, predA) )\n",
        "resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) \n",
        "f1_scoreBMi = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'micro') \n",
        "f1_scoreBMa = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'macro') \n",
        "# confusionMatrix(resultsB,f1_scoreBMi,f1_scoreBMa)\n",
        "print('Confusion Matrix Test Data - Task 2 : ')\n",
        "print(resultsB) \n",
        "print('Accuracy Score Test Data - Task 2 :',accuracy_score(actB, predB) )\n",
        "print('Report Test Data - Task 2 : ')\n",
        "print(classification_report(actB, predB) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix Test Data - Task 1 : \n",
            "[[  0   0   0  37]\n",
            " [  0   0   0  10]\n",
            " [  0   0   0  93]\n",
            " [  0   0   0 360]]\n",
            "Accuracy Score Test Data - Task 1 : 0.72\n",
            "Report Test Data - Task 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        37\n",
            "           1       0.00      0.00      0.00        10\n",
            "           2       0.00      0.00      0.00        93\n",
            "           3       0.72      1.00      0.84       360\n",
            "\n",
            "   micro avg       0.72      0.72      0.72       500\n",
            "   macro avg       0.18      0.25      0.21       500\n",
            "weighted avg       0.52      0.72      0.60       500\n",
            " samples avg       0.72      0.72      0.72       500\n",
            "\n",
            "Confusion Matrix Test Data - Task 2 : \n",
            "[[500]]\n",
            "Accuracy Score Test Data - Task 2 : 1.0\n",
            "Report Test Data - Task 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00       500\n",
            "\n",
            "   micro avg       1.00      1.00      1.00       500\n",
            "   macro avg       1.00      1.00      1.00       500\n",
            "weighted avg       1.00      1.00      1.00       500\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "mByLB8_5Ixck",
        "colab_type": "code",
        "outputId": "fad3f29a-75c1-4c56-8cc6-79b34a46bc12",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1085
        }
      },
      "cell_type": "code",
      "source": [
        "predicted = model.predict([in2Vali[0:5000],in1Vali[0:5000]])\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.show()\n",
        "[predA,predB] = predicted\n",
        "print(predA.shape,predB.shape)\n",
        "actA,actB = out2Vali[0:5000],out1Vali[0:5000]\n",
        "actB = actB.reshape(5000,1)\n",
        "print(actA.shape,actB.shape)\n",
        "predA = (predA > 0.5)*1\n",
        "predB = (predB > 0.5)*1\n",
        "\n",
        "resultsA = confusion_matrix(actA.argmax(axis=1), predA.argmax(axis=1)) \n",
        "# confusionMatrix(resultsA)\n",
        "f1_scoreAMi = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'micro') \n",
        "f1_scoreAMa = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'macro') \n",
        "# confusionMatrix(resultsA,f1_scoreAMi,f1_scoreAMa)\n",
        "print('Confusion Matrix Train Data - Task 1 : ')\n",
        "print(resultsA) \n",
        "print('Accuracy Score Train Data - Task 1 :',accuracy_score(actA, predA) )\n",
        "print('Report Train Data - Task 1 : ')\n",
        "print(classification_report(actA, predA) )\n",
        "resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) \n",
        "resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) \n",
        "f1_scoreBMi = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'micro') \n",
        "f1_scoreBMa = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'macro') \n",
        "# confusionMatrix(resultsB,f1_scoreBMi,f1_scoreBMa)\n",
        "print('Confusion Matrix Train Data - Task 2 : ')\n",
        "print(resultsB) \n",
        "print('Accuracy Score Train Data - Task 2 :',accuracy_score(actB, predB) )\n",
        "print('Report Train Data - Task 2 : ')\n",
        "print(classification_report(actB, predB) )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niAQUCCIiAigQREQkoEAQEREA/j+/Yv+opBzGYwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(5000, 4) (5000, 1)\n",
            "(5000, 4) (5000, 1)\n",
            "Confusion Matrix Train Data - Task 1 : \n",
            "[[   0    0    0  371]\n",
            " [   0    0    0   85]\n",
            " [   0    0    1  906]\n",
            " [   0    0    0 3637]]\n",
            "Accuracy Score Train Data - Task 1 : 0.7276\n",
            "Report Train Data - Task 1 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       371\n",
            "           1       0.00      0.00      0.00        85\n",
            "           2       1.00      0.00      0.00       907\n",
            "           3       0.73      1.00      0.84      3637\n",
            "\n",
            "   micro avg       0.73      0.73      0.73      5000\n",
            "   macro avg       0.43      0.25      0.21      5000\n",
            "weighted avg       0.71      0.73      0.61      5000\n",
            " samples avg       0.73      0.73      0.73      5000\n",
            "\n",
            "Confusion Matrix Train Data - Task 2 : \n",
            "[[5000]]\n",
            "Accuracy Score Train Data - Task 2 : 0.6854\n",
            "Report Train Data - Task 2 : \n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.69      1.00      0.81      3427\n",
            "           1       0.00      0.00      0.00      1573\n",
            "\n",
            "   micro avg       0.69      0.69      0.69      5000\n",
            "   macro avg       0.34      0.50      0.41      5000\n",
            "weighted avg       0.47      0.69      0.56      5000\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
            "  'precision', 'predicted', average, warn_for)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}