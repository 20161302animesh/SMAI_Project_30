# -*- coding: utf-8 -*-
"""Proj-v1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Bg0XeK3a4Y5M7LhnedhVizZuHHBL16va
"""

# Code to read csv file into Colaboratory:
!pip install -U -q PyDrive
import numpy as np
import pandas as pd
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials
# Authenticate and create the PyDrive client.
auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

link = 'https://drive.google.com/open?id=1Ka7fNnL71IH-BV010DhTLU9Drlmqt3o9'
fluff, id = link.split('=')
print (id) # Verify that you have everything after '='
downloaded = drive.CreateFile({'id':id}) 
downloaded.GetContentFile('rumour.npy')  
file_dict = np.load('rumour.npy',allow_pickle=True)

link1 = 'https://drive.google.com/open?id=1KaglTR_T2tQcxsHl5jSuXtmlcWJTk4ZY'
fluff1, id1 = link1.split('=')
print (id1) # Verify that you have everything after '='
downloaded1 = drive.CreateFile({'id':id1}) 
downloaded1.GetContentFile('fakenews.npy')  
file_dict1 = np.load('fakenews.npy',allow_pickle=True)

out1Val = file_dict[:,1]
in1Val = file_dict[:,0]
print(in1Val.shape)
out2Val = file_dict1[:,1]
in2Val = file_dict1[:,0]
print(in2Val.shape)

def pad_along_axis(array: np.ndarray, target_length, axis=0):

    pad_size = target_length - array.shape[axis]
    axis_nb = len(array.shape)

    if pad_size < 0:
        return array[:target_length]
    npad = [(0, 0) for x in range(axis_nb)]
    npad[axis] = (0, pad_size)

    b = np.pad(array, pad_width=npad, mode='constant', constant_values=0)

    return b
  

shapes = [ar.shape[0] for ar in in1Val]
maxLeng1 =  np.max(shapes)
shapes = [ar.shape[0] for ar in in2Val]
maxLeng2 =  np.max(shapes)
maxLeng  = maxLeng1
if(maxLeng < maxLeng2):
  maxLeng = maxLeng2

timeSteps = 200

in2ValX = in1Val
temp = [pad_along_axis(in2ValAR, timeSteps, axis=0) for in2ValAR in in2ValX]
# in1Vali = [np.pad(in1ValAR, (0,maxLeng-in1ValAR.shape[0]), 'constant', constant_values=(0, 0)) for in1ValAR in in1ValX]
# shapes1 = [[ar.shape] for ar in in1Vali]
#print(shapes1)
in1Vali = np.array(temp)
print(in1Vali.shape)

in1ValX = None
in1ValX = in2Val
temp = [pad_along_axis(in1ValAR, timeSteps, axis=0) for in1ValAR in in1ValX]
# in1Vali = [np.pad(in1ValAR, (0,maxLeng-in1ValAR.shape[0]), 'constant', constant_values=(0, 0)) for in1ValAR in in1ValX]
#print(shapes1)
in2Vali = np.array(temp)
print(in2Vali.shape)

# print(np.unique(out1Val,return_counts=True))
out1Vali = [1 if val=='rumours' else 0 for val in out1Val]
out1Vali = np.array(out1Vali)
# print(np.unique(out1Vali,return_counts=True))

# print(np.unique(out2Val,return_counts=True))
def findInt(valu):
  if valu == 'agree':
    return np.array([1,0,0,0])
  elif valu == 'disagree':
    return np.array([0,1,0,0])
  elif valu == 'discuss':
    return np.array([0,0,1,0])
  else:
    return np.array([0,0,0,1])
out2Vali = [findInt(val) for val in out2Val]
out2Vali = np.array(out2Vali)
#print(out2Vali.shape,out2Val.shape,out2Val[0:5],out2Vali[0:5,:])

# from sklearn.cross_validation import train_test_split
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM, GRU
from keras.optimizers import RMSprop
import matplotlib.pyplot as plt
# Data = [[[(i+j)/100] for i in np.arange(5)] for j in np.arange(100)]
# target = [1 if (i%5)==0 else 0 for i in np.arange(100)]
# x_train = np.array(Data,dtype=float)
# y_train = np.array(target,dtype=float)
# # print(x_train,y_train)
# Data = [[[(i+j)/200] for i in np.arange(5)] for j in np.arange(100)]
# target = [1 if (i%5)==0 else 0 for i in np.arange(100)]
# x_test = np.array(Data,dtype=float)
# y_test = np.array(target,dtype=float)
# # print(x_test,y_test)
# # x_train,x_test,y_train,y_test = train_test_split(data,target,size=0.2,random_state=4)
# model=Sequential()
# model.add(LSTM((1),batch_input_shape=(None,5,1),return_sequences=False))
# # model.add(Dense((1),activation='softmax'))
# model.compile(loss='mean_absolute_error',optimizer='adam',metrics=['accuracy'])
# model.summary()

# history = model.fit(x_train,y_train,epochs=10,validation_data=(x_test,y_test))
# results = model.predict(x_test)
# plt.scatter(np.arange(100),results,c='r')
# plt.scatter(np.arange(100),y_test,c='g')
# plt.show()

# plt.plot(history.history['loss'])
# plt.show()

from keras.layers import Input,concatenate
from keras.models import Model
# define two sets of inputs
print
inputA = Input(shape=(None,300))
inputB = Input(shape=(None,300))
 
# the first branch operates on the first input
x1 = Dense(300, activation="linear")(inputA)
x1 = Model(inputs=inputA, outputs=x1)
 
# the second branch opreates on the second input

x2 = Dense(300, activation="linear")(inputB)
x2 = Model(inputs=inputB, outputs=x2)

combinedinput = concatenate([x1.output, x2.output])
# combinedinputDense = Dense(300, activation="linear")(combinedinput)
sharedLOut = GRU((300),return_sequences=True)(combinedinput)
# sharedLayerModel = Model(inputs=combinedinput, output=sharedLOut)

model1Input = concatenate([x1.output, sharedLOut])
model1Out = GRU((4),return_sequences=False)(model1Input)
# model1 = Model(inputs=model1Input, output=model1Out)


model2Input = concatenate([x2.output, sharedLOut])
model2Out = GRU((1),return_sequences=False)(model2Input)
# model2 = Model(inputs=model2Input, output=model2Out)
model = Model(input=[inputA,inputB], outputs=[model1Out,model2Out])
optimizer = RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=0.0)
model.compile(loss='mse', optimizer=optimizer)
model.summary()

# history = {}
# results = {}
# for j in np.arange(10):
#   i = j
#   X2_train = in1Val[i]
#   Y2_train = out1Vali[i]
#   X2_train = X2_train.reshape(1,*X2_train.shape)
#   Y2_train = Y2_train.reshape(1,1)
#   X1_train = in2Val[i]
#   Y1_train = out2Vali[i]
#   X1_train = X1_train.reshape(1,*X1_train.shape)
#   Y1_train = Y1_train.reshape(1,*Y1_train.shape)
#   i = int(j/2)
#   X2_test = in1Val[i]
#   Y2_test = out1Vali[i]
#   X2_test = X2_test.reshape(1,*X2_test.shape)
#   Y2_test = Y2_test.reshape(1,1)
#   X1_test = in2Val[i]
#   Y1_test = out2Vali[i]
#   X1_test = X1_test.reshape(1,*X1_test.shape)
#   Y1_test = Y1_test.reshape(1,*Y1_test.shape)
# history = model.fit([X1_train,X2_train],[Y1_train,Y2_train],epochs=10,validation_data=([X1_test,X2_test],[Y1_test,Y2_test]))
# results = model.predict(x_test)
history = model.fit([in2Vali[0:4500],in1Vali[0:4500]],[out2Vali[0:4500],out1Vali[0:4500]],batch_size=100,epochs=100,validation_data=([in2Vali[4500:5000],in1Vali[4500:5000]],[out2Vali[4500:5000],out1Vali[4500:5000]]))

predicted = model.predict([in2Vali[4500:5000],in1Vali[4500:5000]])

plt.plot(history.history['loss'])
plt.show()

[predA,predB] = predicted
print(predA.shape,predB.shape)
actA,actB = out2Vali[4500:5000],out1Vali[4500:5000]
actB = actB.reshape(500,1)
print(actA.shape,actB.shape)

predA = (predA > 0.5)*1
predB = (predB > 0.5)*1

from sklearn.metrics import f1_score
import seaborn as sns
def confusionMatrix(cm,f1mi, f1ma):
    #T_class = list(map(int,y_adm_val >= t ))
    #out = predict(X_adm_val,Theta,t,Mean,Std)
#     cm = confusion_matrix(a, b)
    ax= plt.subplot()
    sns.heatmap(cm, annot=True, ax = ax); #annot=True to annotate cells

    # labels, title and ticks
    ax.set_xlabel('Predicted labels');ax.set_ylabel('True labels'); 
    ax.set_title('Confusion Matrix'); 
    #ax.xaxis.set_ticklabels(['1', '0']); ax.yaxis.set_ticklabels(['1', '0'])
    print("Micro-F1-score",f1mi)
    print("Macro-F1-score",f1ma)
#     print("precision",precision_score(T_class,out, average = 'micro'))
#     print("Accuracy",accuracy_score(T_class,out))
#     print("Recall",recall_score(T_class,out, average = 'micro'))

from sklearn.metrics import confusion_matrix 
from sklearn.metrics import accuracy_score 
from sklearn.metrics import classification_report 
resultsA = confusion_matrix(actA.argmax(axis=1), predA.argmax(axis=1)) 
f1_scoreAMi = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'micro') 
f1_scoreAMa = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'macro') 
# confusionMatrix(resultsA,f1_scoreAMi,f1_scoreAMa)
print('Confusion Matrix Test Data - Task 1 : ')
print(resultsA) 
print('Accuracy Score Test Data - Task 1 :',accuracy_score(actA, predA) )
print('Report Test Data - Task 1 : ')
print(classification_report(actA, predA) )
resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) 
f1_scoreBMi = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'micro') 
f1_scoreBMa = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'macro') 
# confusionMatrix(resultsB,f1_scoreBMi,f1_scoreBMa)
print('Confusion Matrix Test Data - Task 2 : ')
print(resultsB) 
print('Accuracy Score Test Data - Task 2 :',accuracy_score(actB, predB) )
print('Report Test Data - Task 2 : ')
print(classification_report(actB, predB) )

predicted = model.predict([in2Vali[0:5000],in1Vali[0:5000]])

plt.plot(history.history['loss'])
plt.show()
[predA,predB] = predicted
print(predA.shape,predB.shape)
actA,actB = out2Vali[0:5000],out1Vali[0:5000]
actB = actB.reshape(5000,1)
print(actA.shape,actB.shape)
predA = (predA > 0.5)*1
predB = (predB > 0.5)*1

resultsA = confusion_matrix(actA.argmax(axis=1), predA.argmax(axis=1)) 
# confusionMatrix(resultsA)
f1_scoreAMi = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'micro') 
f1_scoreAMa = f1_score(actA.argmax(axis=1), predA.argmax(axis=1), average = 'macro') 
# confusionMatrix(resultsA,f1_scoreAMi,f1_scoreAMa)
print('Confusion Matrix Train Data - Task 1 : ')
print(resultsA) 
print('Accuracy Score Train Data - Task 1 :',accuracy_score(actA, predA) )
print('Report Train Data - Task 1 : ')
print(classification_report(actA, predA) )
resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) 
resultsB = confusion_matrix(actB.argmax(axis=1), predB.argmax(axis=1)) 
f1_scoreBMi = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'micro') 
f1_scoreBMa = f1_score(actB.argmax(axis=1), predB.argmax(axis=1), average = 'macro') 
# confusionMatrix(resultsB,f1_scoreBMi,f1_scoreBMa)
print('Confusion Matrix Train Data - Task 2 : ')
print(resultsB) 
print('Accuracy Score Train Data - Task 2 :',accuracy_score(actB, predB) )
print('Report Train Data - Task 2 : ')
print(classification_report(actB, predB) )